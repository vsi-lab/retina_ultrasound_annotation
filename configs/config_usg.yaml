# configs/config_usg.yaml
seed: 42
work_root: "/Users/saurav1/python/masters/arizona/2nd/fall/retina_ultrasound_annotation/work_dir"


data:
  num_classes: 5                           # Number of segmentation classes (excluding background)
  class_names: ["background", "vitreous_humor", "retina", "optic_nerve", "choroid"]
  labels:                                  # Mapping from class name to integer ID
    background: 0
    vitreous_humor: 1
    retina: 2
    optic_nerve: 3
    choroid: 4
#  class_names: ["background", "retina", "choroid"]
#  labels:                                  # Mapping from class name to integer ID
#    background: 0
#    retina: 1   # shift 2 to 1
#    choroid: 2  # shift 4 to 2

  work_dir: "{work_root}"                       # Base directory for current experiment
  out_dir: data                            # Folder for generated CSVs (train/val/test)

  reader: auto                             # Automatically selects cv2 or PIL for reading
  train_csv: "{work_root}/metadata/train.csv"
  val_csv:   "{work_root}/metadata/val.csv"
  test_csv:  "{work_root}/metadata/test.csv"

#  resize: [800, 1280]                       # Target spatial resolution (HxW)
  resize: [512, 512]                       # Target spatial resolution (HxW)
  normalize: zscore                        # Normalization type: zscore|minmax|log
  despeckle: median3                       # Apply median filter for speckle reduction
  fan_mask: none                           # For optional sector cropping (none|left|right|center)
  return_path: true

  mask_mode: grayscale          # auto | grayscale | color  (auto = detect by channels)
#  color_palette:           # used if mask is color (BGR as saved by cv2)
#    background: [0, 0, 0]
#    retina: [0, 255, 0]
#    choroid: [0, 255, 255]
#    vitreous_humor: [255, 0,  255]  # example; set actual colors to  use
#    optic_nerve: [124, 124,  255]  # example; set actual colors to  use


model:
  # unet++ pretrained
#  name: unetpp
#  encoder_name: resnet50       # for SMP backbones (unetpp/unet); e.g., resnet34 | resnet50
#  encoder_weights: imagenet

  # ViT
  name: transunet_npz
  # Path to Google ViT .npz (ImageNet-21k pretraining). Example below is ViT-B/16.
  pretrained_npz: "{work_root}/vit_checkpoint/imagenet21k/ViT-L_16.npz"
  encoder_name: "ViT-L_16"
#  pretrained_npz: "{work_root}/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz"
#  encoder_name: "R50-ViT-B_16"
  n_channels: 1
  img_size: 512   # make sure  letterbox/resize yields multiples of patch_size
  n_skip: 3
  # ViT/TransUNet ends

aug:
  hflip: 0.0                               # Horizontal flip probability
  rotate_deg: [-5, 5]                      # Random rotation range (degrees)
  scale: [0.98, 1.02]                      # Random scale factor range
  translate: [-0.02, 0.02]                 # Random translation (fraction of width/height)
  shear_deg: [-2, 2]                       # Random shear range (degrees)
  brightness: [0.95, 1.05]                 # Random brightness adjustment
  contrast: [0.95, 1.05]                   # Random contrast adjustment
  gaussian_noise_std: 0.01                 # Speckle noise standard deviation
  p: 0.9                                   # Overall augmentation probability

train:
  batch_size: 4                            # Images per batch
  epochs: 20  # 40                               # Number of training epochs
  lr: 1.0e-3                               # Initial learning rate
  weight_decay: 1.0e-5                     # L2 regularization
  previews_per_epoch: 2
  early_stop_patience: 5
  early_stop_min_delta: 0.001
  num_workers : 0 # 0 required for Transunet

loss:
  dice_weight: 0.7                         # Dice contribution
#  focal_weight: 0.3                        # Focal contribution
  focal_weight: 0.0                        # Focal contribution
  focal_gamma: 2.0                         # Focal focusing parameter

eval:
  threshold: 0.5                           # Sigmoid threshold for binary segmentation

# Split by Patient (avoid leakage)
splits:
  train: ["Patient1", "Patient2", "Patient3", "Patient4", "Patient8"]
  val:   ["Patient5"]
  test:  ["Patient6", "Patient7"]

#  train_frac: 0.7
#  val_frac: 0.15
#  test_frac: 0.15
  seed: 42
  stratify_by_rd: true                     # Ensures even distribution of RD cases
